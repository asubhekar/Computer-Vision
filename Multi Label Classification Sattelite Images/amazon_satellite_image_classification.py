# -*- coding: utf-8 -*-
"""Amazon Satellite Image Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aTRrmdzsVlprZaFdckZVxdTPF9obhMs9

# Planets Dataset: Understanding Amazon from Space

In this project, we will be fine-tuning a Vision Transformer model for multi-label image classification task.
In this dataset, we have satellite images of the Amazon rainforest and the task is identify landscape for analyzing the causes of deforestation. Each image in the dataset has 1 or more than 1 labels defining the landscape.

We decided to use the pre trained Swin-S3-base-224 model from Hugging Face.

The dataset used is "Planets Dataset: Understaind Amazon from Space" which can be found here.[Link](https://huggingface.co/datasets/subhuatharva/amazon_from_space)


To power our training loops and for calculating metrics, we will use Hugging Face Accelerate and Hugging Face Evaluate.

## Importing necessary modules and libraries.

Install the necessary packages from the cell below.
"""

!pip install -Uq transformers datasets timm accelerate evaluate

!pip install -Uq pyarrow

import numpy as np
import pandas as pd
from huggingface_hub import login
from datasets import load_dataset
from io import BytesIO
from PIL import Image
import base64
import matplotlib.pyplot as plt
import random

from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torchvision.transforms as T

from transformers.optimization import get_cosine_schedule_with_warmup

from timm import list_models, create_model

from accelerate import Accelerator, notebook_launcher

import evaluate

login()

"""## Dowloading the Dataset

We will download the Satellite image dataset from the Hugging Face hub using datasets library.

"""

data = load_dataset("subhuatharva/amazon_from_space")

data

"""## Creating Images and Labels from the dataset

The Images are in byte IO format which need to be decoded to generate PIL.Image format image.

The Labels are in string formats which need to be one-hot encoded to generate a proper matrix.
"""

def image_decode(byte_image):
    img_bytes = base64.b64decode(byte_image)

    # Convert bytes to a PIL Image
    img = Image.open(BytesIO(img_bytes))
    return img

images = []
for byte_data in data['train']['image']:
    img = image_decode(byte_data)
    images.append(img)

print("Total images in the dataset = ", len(images))

def label_generation(tag):
  # Generating initial labels
  initial_labels = []
  for tag in data['train']['tags']:
    split_tags = tag.split(" ")
    initial_labels.append(split_tags)

  # Getting total number of classes and class names
  flat_list = [item for sublist in initial_labels for item in sublist]
  class_names = list(set(flat_list))
  print("Total Classes {}".format(len(class_names)))
  print("Class names {}".format(class_names))

  # Creating mappings
  label2id = {c:idx for idx,c in enumerate(class_names)}
  id2label = {idx:c for idx,c in enumerate(class_names)}

  return label2id, id2label, initial_labels, class_names

label2id, id2label, initial_labels, class_names = label_generation(data['train']['tags'])

"""Since we have a large dataset, we won't be needing all the sames to demonstrate the efficieny of the model. We will cut down the dataset size to just 15000 samples."""

images = images[:15000]
initial_labels = initial_labels[:15000]

def id_labels_conversion(ini_labels):
  id_labels = []
  for label in ini_labels:
    idlist = []
    for i in label:
      idlist.append(label2id[i])
    id_labels.append(idlist)
  return id_labels

id_labels = id_labels_conversion(initial_labels)

print(initial_labels[1])
print(id_labels[1])

def one_hot_decoding(labels):

  id_list = []
  for idx,i in enumerate(labels):
    if i == 1:
      id_list.append(idx)

  true_labels = []
  for i in id_list:
    true_labels.append(id2label[i])
  return true_labels

temp = one_hot_decoding(test_dataset[0]['labels'])
temp

"""## Displaying some samples from the dataset.

For any dataset we use with the datasets library, we can shuffle the dataset using shuffle() and, select any samples using the select() method.

Some of the images have more than a single label.
"""

def show_samples(ds, labels,rows,cols):
    random_numbers = random.sample(range(len(ds)), rows*cols) # selecting random images
    fig = plt.figure(figsize=(cols*4, rows*4))

    for idx, i in enumerate(random_numbers):
        img = ds[i]
        label = labels[i]
        label = " ".join(label)
        ax = fig.add_subplot(rows, cols, idx + 1)  # specify the position of the subplot
        ax.imshow(img)
        ax.set_title(label)
        ax.axis('off')

    plt.tight_layout()
    plt.show()

show_samples(images, initial_labels, 2, 5)

"""# Preprocessing our Dataset

Since we have a large dataset of total 15000 images we won't have to use synthetic data for training.

But we will resize the image to 224x224 as the model we are planning to use takes fixed size input. Also we will one hot encode the labels.
"""

def one_hot_encoding(labels):
  one_hot_labels = []
  for each_id_label in labels:
    encode_vector = [0 for i in range(len(class_names))]
    for idx in each_id_label:
      encode_vector[idx] = 1
    one_hot_labels.append(encode_vector)
  return one_hot_labels

one_hot_labels = one_hot_encoding(id_labels)

#Splitting the dataset into training, validation and testing set.

train_images, test_images, train_labels, test_labels = train_test_split(images, one_hot_labels, test_size=0.2, random_state=42)
train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)

un_train_dataset = {}
un_val_dataset = {}
un_test_dataset = {}
for i in range(len(train_images)):
  un_train_dataset[i] = {"images": train_images[i], "labels": torch.tensor(train_labels[i], dtype = torch.float32)}

for i in range(len(val_images)):
  un_val_dataset[i] = {"images": val_images[i], "labels": torch.tensor(val_labels[i], dtype = torch.float32)}

for i in range(len(test_images)):
  un_test_dataset[i] = {"images": test_images[i], "labels": test_labels[i]}


print("Total training images = ", len(un_train_dataset))
print("Total validation images = ", len(un_val_dataset))
print("Total testing images = ", len(un_test_dataset))

# Setting the parameters to resize the images.
img_size = (224,224)

train_tfms = T.Compose([
    T.Resize(img_size),
    T.ToTensor(),
    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

test_tfms = T.Compose([
    T.Resize(img_size),
    T.ToTensor(),
])

def transforms(batch):
  print(len(batch))
  for i in range(len(batch)):
    img = batch[i]['images']
    batch[i]['images'] = train_tfms(batch[i]['images'])
  return batch

def test_transforms(batch):
  print(len(batch))
  for i in range(len(batch)):
    img = batch[i]['images']
    batch[i]['images'] = test_tfms(batch[i]['images'])
  return batch

train_dataset = transforms(un_train_dataset)

test_dataset = test_transforms(un_test_dataset)
val_dataset = transforms(un_val_dataset)

def param_count(model):
    params = [(p.numel(),p.requires_grad) for p in model.parameters()]
    trainable = sum([count for count,trainable in params if trainable])
    total = sum([count for count,_ in params])
    frac = (trainable / total) * 100
    return total, trainable, frac

"""---

## Using `timm`

- We can load models from the `timm` library using `timm.create_model`.
- `timm.create_model` arguments:
    - name: name of our model,
    - num_classes: number of classes in our dataset, this will replace the pretrained classifier head of our model with a new head where output features will be equal to num_classes.
    - pretrained: True, to get the pretrained weights of our model.
    
- To list various available models, we can use `timm.list_models`. We can pass in a string pattern such as `*swin*` or `*vit*` which will match all model names available with the pattern. You also also pass `pretrained=True` to only list models with available pretrained weights. Example: `timm.list_models("*swin*",pretrained=True)`


## Writing our own training loops
---

### Components of our loops:

- **DataLoaders**:
    - to iterate over our datasets in batches, we define a dataloader using `torch.utils.data.DataLoader`.
    - we provide the per-device batch size to the dataloader
    - to enable/disable shuffling. True for training but False for validation and testing.
    - num_workers: defines the number of subprocesses which will be used to create our batches, a rule of thumb is to keep it equal to number of CPU cores.
    - collate_fn: we'll pass in the collate function we created earlier.
    
- **Loss Function**:
    - Since after one-hot encoding our labels, our task is equivalent to applying binary classification on each label, we'll be using `nn.BCEWithLogitsLoss()` which will take our predictions and targets of the shape `(batch, num_labels)`
    
- **Model**:
    - The model loaded from the `timm` library.
    
- **Optimizer, Scheduler**:
    - Optimizer updates the weights of our model
    - Scheduler handles the change in the learning rate of our model during training. We'll be using `get_cosine_schedule_with_warmup` from `transformers.optimization`. In this scheduler, the learning rate increases gradually till `num_warmup_steps` and decays for the remaining steps with cosine annealing.

- **Metrics**:
    - we'll calculate metrics using `evaluate` library. We will be using `roc_auc` metric for `multilabel` with `micro` averaging which will calculate the metrics globally. For more explanation and references about the metric, check this [evaluate space](https://huggingface.co/spaces/evaluate-metric/roc_auc).
    

## Using Accelerate to power our loops:

- Accelerate takes care of device placement of our data and model automatically. We define as `accelerator` instance with `Accelerator()` along with any further configuration kwargs.
- We pass our model, dataloaders, optimizer, scheduler via `accelerator.prepare` method.
- To calculate metrics, we need to gather our batches from all devices, hence we use `accelerator.gather_for_metrics` to do so.
- To print only on the main process, we will use `accelerator.print`.


Since we'll be running from our Jupyter notebook, we'll be using `notebook_launcher`, which will call our `train` function that contains all of our logic and `accelerator` instance.


For further information and details on how to use `accelerate`, checkout the [docs](https://huggingface.co/docs/accelerate/index) and this handy [HF space](https://huggingface.co/spaces/hf-accelerate/accelerate_examples).
"""

def train(model_name,batch_size=16,epochs=1,lr=2e-4):
    """
    contains all of our training loops.
    1. define Accelerator instance
    2. define dataloaders, model, optimizer, loss function, scheduler
    3. write training, validation and testing loop.
    """

    accelerator = Accelerator() # create instance

    # define dataloaders

    train_dl = torch.utils.data.DataLoader(
        train_dataset,
        batch_size = batch_size, # the batch_size will be per-device
        shuffle=True,
        num_workers=4,
        #collate_fn=collate_fn
    )

    valid_dl = torch.utils.data.DataLoader(
        val_dataset,
        batch_size = batch_size*2,
        shuffle=False,
        num_workers=4,
        #collate_fn=collate_fn
    )

    test_dl = torch.utils.data.DataLoader(
        test_dataset,
        batch_size = batch_size*2,
        shuffle=False,
        num_workers=4,
        #collate_fn=collate_fn
    )

    # timm model
    model = create_model(
        model_name,
        pretrained = True,
        num_classes = 17
    ).to(accelerator.device) # device placement: accelerator.device

    total, trainable, frac = param_count(model)
    accelerator.print(f"{total = :,} | {trainable = :,} | {frac:.2f}%")

    # loss, optimizer, scheduler

    loss_fn = nn.BCEWithLogitsLoss()

    optimizer = torch.optim.AdamW(model.parameters(),lr=lr,weight_decay=0.02)

    scheduler = get_cosine_schedule_with_warmup(
        optimizer,
        num_warmup_steps = int(0.1 * len(train_dl)),
        num_training_steps=len(train_dl)
    )

    model, optimizer, scheduler, train_dl, valid_dl, test_dl = accelerator.prepare(
        model, optimizer, scheduler, train_dl, valid_dl, test_dl
    )

    # loops for number of epochs
    for epoch in range(1,epochs+1):

        model.train() # set model to train

        train_metric = evaluate.load('roc_auc','multilabel') # load metric

        running_loss = 0.

        for batch in train_dl:

            logits = model(batch['images'])

            loss = loss_fn(logits,batch['labels'])
            accelerator.backward(loss) # backpropagation
            optimizer.step() # update weights
            scheduler.step() # update LR
            optimizer.zero_grad() # set grad values to zero

            running_loss += loss.item() # keep track of loss

            # prepare for metrics
            logits, labels = accelerator.gather_for_metrics(
                (logits, batch['labels'])
            )
            train_metric.add_batch(references=labels, prediction_scores=logits)

        # loss and metric over 1 epoch
        train_loss = running_loss / len(train_dl)
        train_roc_auc = train_metric.compute(average='micro')['roc_auc']

        accelerator.print(f"\n{epoch = }")
        accelerator.print(f"{train_loss = :.3f} | {train_roc_auc = :.3f}")

        # validation loop

        model.eval() # set model for evaluation

        running_loss = 0.
        valid_metric = evaluate.load('roc_auc','multilabel')

        for batch in valid_dl:

            with torch.no_grad():
                logits = model(batch['images'])

            loss = loss_fn(logits, batch['labels'])
            running_loss += loss.item()

            logits, labels = accelerator.gather_for_metrics(
                (logits, batch['labels'])
            )
            valid_metric.add_batch(references=labels, prediction_scores=logits)


        valid_loss = running_loss / len(valid_dl)
        valid_roc_auc = valid_metric.compute(average='micro')['roc_auc']

        accelerator.print(f"{valid_loss = :.3f} | {valid_roc_auc = :.3f}")

        # save model
        accelerator.save_model(model, f'./{model_name}-Satellite-Image')


    # testing loop after all epochs are over

    test_metric = evaluate.load('roc_auc','multilabel')

    for batch in test_dl:

        with torch.no_grad():
            logits = model(batch['images'])

        logits, labels = accelerator.gather_for_metrics(
            (logits, batch['labels'])
        )
        test_metric.add_batch(references=labels, prediction_scores=logits)

    test_roc_auc = test_metric.compute(average='micro')['roc_auc']

    accelerator.print(f"\n\nTEST AUROC: {test_roc_auc:.3f}")

"""## Training our model

Using notebook launcher, we start the training procedue by calling our train funciton with the args (model_nam, batch_size, epochs, learning_rate) as we defined above, and num_processes equal to the amount of GPUs.
"""

model_name = 'swin_s3_base_224'
notebook_launcher(train, (model_name,8,5,5e-5), num_processes = 2)

"""## Evaluation

Our proposed model seems to be doing great without needing many epochs and with less than half the size of the whole dataset.

We will save the model using accelerate.save_model.

## Finally we can get some predictions on the Test data and see the final results.
"""

from safetensors.torch import load_model

# intialize the model
model = create_model(
    model_name,
    num_classes=17
)

load_model(model,f'./{model_name}-Satellite-Images/model.safetensors')

rows = 2
cols = 4
model.eval()
random_numbers = random.sample(range(len(test_dataset)), rows*cols) # selecting random images
fig = plt.figure(figsize=(cols*4, rows*4))

for idx, i in enumerate(random_numbers):
  img = test_dataset[i]["images"]
  one_hot_test_labels = test_dataset[i]["labels"]
  true_labels = one_hot_decoding(one_hot_test_labels)

  with torch.no_grad():
    logits = model(img.unsqueeze(0))

  predictions = logits.sigmoid() > 0.5
  predictions = predictions.float().numpy().flatten()
  pred_labels = one_hot_decoding(predictions)

  label = f"labels: {true_labels}\npredicted: {pred_labels}"

  ax = fig.add_subplot(rows, cols, idx + 1)  # specify the position of the subplot

  # Transpose the image tensor to the format expected by imshow
  img_to_show = img.permute(1, 2, 0)
  ax.imshow(img_to_show)

  ax.set_title(label, fontsize=10)
  ax.axis('off')